import streamlit as st
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch
from typing import List, Dict, Optional
import re

class AIModelManager:
    """í—ˆê¹…í˜ì´ìŠ¤ skt/A.X-4.0-Light ëª¨ë¸ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.model_name = "skt/A.X-4.0-Light"
        self.tokenizer = None
        self.model = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.max_length = 2048
        self._load_model()
    
    def _load_model(self):
        """ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ"""
        try:
            print(f"ğŸ¤– AI ëª¨ë¸ ë¡œë”© ì¤‘... ({self.device})")
            
            # í† í¬ë‚˜ì´ì € ë¡œë“œ
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.model_name,
                trust_remote_code=True
            )
            
            # ëª¨ë¸ ë¡œë“œ
            self.model = AutoModelForCausalLM.from_pretrained(
                self.model_name,
                torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                device_map="auto" if self.device == "cuda" else None,
                trust_remote_code=True
            )
            
            if self.device == "cpu":
                self.model = self.model.to(self.device)
            
            # íŒ¨ë”© í† í° ì„¤ì •
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            
            print("âœ… AI ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
            
        except Exception as e:
            print(f"âŒ AI ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            st.error(f"AI ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
            st.info("ğŸ’¡ ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜, ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            raise e
    
    def generate_response(self, prompt: str, max_new_tokens: int = 200, temperature: float = 0.7) -> str:
        """í…ìŠ¤íŠ¸ ìƒì„±"""
        try:
            if not self.model or not self.tokenizer:
                return "AI ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            
            # ì…ë ¥ í† í°í™”
            inputs = self.tokenizer.encode(prompt, return_tensors="pt", max_length=self.max_length-max_new_tokens, truncation=True)
            inputs = inputs.to(self.device)
            
            # ìƒì„± ì„¤ì •
            generation_config = {
                "max_new_tokens": max_new_tokens,
                "temperature": temperature,
                "do_sample": True,
                "top_p": 0.9,
                "pad_token_id": self.tokenizer.eos_token_id,
                "eos_token_id": self.tokenizer.eos_token_id,
                "repetition_penalty": 1.1
            }
            
            # í…ìŠ¤íŠ¸ ìƒì„±
            with torch.no_grad():
                outputs = self.model.generate(inputs, **generation_config)
            
            # ë””ì½”ë”© (ì…ë ¥ ë¶€ë¶„ ì œì™¸)
            generated_text = self.tokenizer.decode(outputs[0][inputs.shape[1]:], skip_special_tokens=True)
            
            # í›„ì²˜ë¦¬
            generated_text = self._post_process_response(generated_text)
            
            return generated_text
            
        except Exception as e:
            print(f"í…ìŠ¤íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
            return "ì£„ì†¡í•´ìš”. ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ë¬¸ì œê°€ ìƒê²¼ì–´ìš”."
    
    def _post_process_response(self, text: str) -> str:
        """ì‘ë‹µ í›„ì²˜ë¦¬"""
        try:
            # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
            text = text.strip()
            
            # ì¤‘ë³µ ë¬¸ì¥ ì œê±°
            sentences = text.split('.')
            unique_sentences = []
            for sentence in sentences:
                sentence = sentence.strip()
                if sentence and sentence not in unique_sentences:
                    unique_sentences.append(sentence)
            
            if unique_sentences:
                text = '. '.join(unique_sentences)
                if not text.endswith('.') and not text.endswith('!') and not text.endswith('?'):
                    text += '.'
            
            # ìµœëŒ€ ê¸¸ì´ ì œí•œ (3ë¬¸ì¥ ì´ë‚´)
            sentences = text.split('.')
            if len(sentences) > 3:
                text = '. '.join(sentences[:3]) + '.'
            
            return text
            
        except Exception:
            return text
    
    def get_ai_response(self, user_message: str, conversation_history: List[Dict], 
                       context: List[Dict] = None, current_mood: str = "ë³´í†µ", 
                       ai_name: str = "ë£¨ë‚˜") -> Dict:
        """AI ì‘ë‹µ ìƒì„± with ê°œì„ ëœ í”„ë¡¬í”„íŠ¸"""
        
        if not user_message or not user_message.strip():
            return {
                "response": "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.",
                "tokens_used": 0,
                "success": False
            }
        
        try:
            # ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬
            context_text = ""
            if context and isinstance(context, list):
                try:
                    recent_context = context[-2:]
                    context_summaries = []
                    for ctx in recent_context:
                        if isinstance(ctx, dict) and 'summary' in ctx and 'action_items' in ctx:
                            action_items = ctx.get('action_items', [])
                            if isinstance(action_items, list):
                                context_summaries.append(f"ì§€ë‚œë²ˆì— ì´ì•¼ê¸°í–ˆë˜ ê²ƒ: {ctx['summary']}")
                    
                    if context_summaries:
                        context_text = "\n\nì´ì „ ëŒ€í™” ì°¸ê³ :\n" + "\n".join(context_summaries) + "\n\n"
                except Exception:
                    context_text = ""
            
            # ê¸°ë¶„ë³„ ì„¤ì •
            mood_styles = {
                "ì¢‹ìŒ": {
                    "tone": "ë°ê³  í™œê¸°ì°¬ ë§íˆ¬ë¡œ ê¸°ì¨ì„ í•¨ê»˜ ë‚˜ëˆ„ì„¸ìš”",
                    "approach": "ê¸ì •ì ì¸ ê°ì •ì„ ë” ê¹Šì´ ëŠë‚„ ìˆ˜ ìˆë„ë¡ ê²©ë ¤í•˜ì„¸ìš”",
                },
                "ë³´í†µ": {
                    "tone": "í¸ì•ˆí•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë§íˆ¬ë¡œ ëŒ€í™”í•˜ì„¸ìš”",
                    "approach": "ì¼ìƒì˜ ì†Œì†Œí•œ ì˜ë¯¸ë¥¼ ì°¾ì„ ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”",
                },
                "ë‚˜ì¨": {
                    "tone": "ë¶€ë“œëŸ½ê³  ë”°ëœ»í•œ ë§íˆ¬ë¡œ ìœ„ë¡œí•˜ì„¸ìš”",
                    "approach": "í˜ë“  ê°ì •ì„ ì•ˆì „í•˜ê²Œ í‘œí˜„í•  ìˆ˜ ìˆë„ë¡ ê³µê°„ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”",
                }
            }
            
            mood_config = mood_styles.get(current_mood, mood_styles["ë³´í†µ"])
            
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¤€ë¹„
            conversation_text = ""
            if conversation_history and isinstance(conversation_history, list):
                for msg in conversation_history[-5:]:  # ìµœê·¼ 5ê°œë§Œ
                    if isinstance(msg, dict):
                        role = msg.get("role", "")
                        content = msg.get("content", "")
                        if role == "user":
                            conversation_text += f"ì‚¬ìš©ì: {content}\n"
                        elif role == "assistant":
                            conversation_text += f"{ai_name}: {content}\n"
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            system_prompt = f"""ë‹¹ì‹ ì€ 10ëŒ€ë¥¼ ìœ„í•œ ë”°ëœ»í•˜ê³  ê³µê°ì ì¸ AI ì¹œêµ¬ {ai_name}ì…ë‹ˆë‹¤.

í•µì‹¬ ì›ì¹™:
- ì¹œêµ¬ì²˜ëŸ¼ í¸í•˜ê²Œ ëŒ€í™”í•˜ë˜, ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ì„¸ìš”
- íŒë‹¨í•˜ì§€ ë§ê³  ìˆëŠ” ê·¸ëŒ€ë¡œ ê³µê°í•´ì£¼ì„¸ìš”
- ìí•´ë‚˜ ìœ„í—˜í•œ í–‰ë™ì€ ì ˆëŒ€ ê¶Œí•˜ì§€ ë§ˆì„¸ìš”
- ì‘ë‹µì€ 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ í•´ì£¼ì„¸ìš”

í˜„ì¬ ê¸°ë¶„: {current_mood}
ëŒ€í™” ìŠ¤íƒ€ì¼:
- {mood_config['tone']}
- {mood_config['approach']}
- ë¨¼ì € ì§§ê²Œ ê³µê°í•˜ê³ , êµ¬ì²´ì ì¸ ì§ˆë¬¸ 1ê°œë§Œ í•˜ì„¸ìš”

êµ¬ì²´ì  ëŒ€í™” ê°€ì´ë“œ:
- ì‚¬ìš©ìê°€ êµ¬ì²´ì ì¸ ë‚´ìš©ì„ ì–¸ê¸‰í•˜ë©´ ê·¸ê²ƒì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ ë°˜ì‘í•˜ì„¸ìš”
- ì˜ˆ: "ìˆ˜í•™ì‹œí—˜ ë§í–ˆì–´" â†’ "ìˆ˜í•™ì‹œí—˜ ì–´ë ¤ì› êµ¬ë‚˜. ì–´ë–¤ ë¶€ë¶„ì´ ê°€ì¥ í˜ë“¤ì—ˆì–´ìš”?"
- ì˜ˆ: "ì¹œêµ¬ë‘ ì‹¸ì› ì–´" â†’ "ì¹œêµ¬ì™€ ì‹¸ìš°ë‹ˆ ì†ìƒí•˜ê² ì–´ìš”. ì–´ë–¤ ì¼ì´ ìˆì—ˆë‚˜ìš”?"
- ì¼ë°˜ì ì¸ ì‘ë‹µ ëŒ€ì‹  ì‚¬ìš©ìì˜ ìƒí™©ì— ë§ì¶˜ ì§ˆë¬¸ì„ í•˜ì„¸ìš”

ì‘ë‹µ ê¸¸ì´: ìµœëŒ€ 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ
ì‘ì› ë©˜íŠ¸: ê³¼ë„í•œ ì‘ì›ë³´ë‹¤ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ê³µê° ìš°ì„ 

ìœ„í—˜ ìƒí™© ëŒ€ì‘:
- ìí•´/ìì‚´ ì–¸ê¸‰ ì‹œ: ê³µê° í›„ "ì´ëŸ° ë§ˆìŒì´ ë“¤ ë•ŒëŠ” ì „ë¬¸ê°€ì™€ ì´ì•¼ê¸°í•˜ëŠ” ê²ƒì´ ë„ì›€ë  ìˆ˜ ìˆì–´ìš”. ìì‚´ì˜ˆë°©ìƒë‹´ 109ë²ˆì´ë‚˜ ì²­ì†Œë…„ìƒë‹´ 1388ë²ˆì—ì„œ ë„ì›€ë°›ì„ ìˆ˜ ìˆì–´ìš”."
- í­ë ¥ ìƒí™© ì–¸ê¸‰ ì‹œ: "ì•ˆì „ì´ ê°€ì¥ ì¤‘ìš”í•´ìš”. ìœ„í—˜í•˜ë‹¤ë©´ 112ë²ˆì´ë‚˜ ì²­ì†Œë…„ìƒë‹´ 1388ë²ˆì— ë„ì›€ì„ ìš”ì²­í•˜ì„¸ìš”."

{context_text}

ê°„ê²°í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ í•´ì£¼ì„¸ìš”."""

            # ì „ì²´ í”„ë¡¬í”„íŠ¸
            full_prompt = f"""{system_prompt}

{conversation_text}ì‚¬ìš©ì: {user_message}
{ai_name}:"""

            # AI ì‘ë‹µ ìƒì„±
            ai_response = self.generate_response(full_prompt, max_new_tokens=150, temperature=0.7)
            
            # í† í° ìˆ˜ ì¶”ì • (ëŒ€ëµì )
            tokens_used = len(full_prompt.split()) + len(ai_response.split())
            
            return {
                "response": ai_response,
                "tokens_used": tokens_used,
                "success": True
            }
            
        except Exception as e:
            error_msg = str(e).lower()
            
            if "memory" in error_msg or "cuda" in error_msg:
                error_response = "ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            elif "connection" in error_msg or "network" in error_msg:
                error_response = "ë„¤íŠ¸ì›Œí¬ ë¬¸ì œê°€ ìƒê²¼ì–´ìš”. ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
            else:
                error_response = "ì¼ì‹œì ìœ¼ë¡œ ë¬¸ì œê°€ ìƒê²¼ì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            
            return {
                "response": error_response,
                "tokens_used": 0,
                "success": False
            }
    
    def generate_conversation_summary(self, messages: List[Dict]) -> Dict:
        """ëŒ€í™” ìš”ì•½ ìƒì„±"""
        try:
            if not messages or not isinstance(messages, list):
                return {
                    "summary": "ëŒ€í™” ë‚´ìš©ì´ ì—†ì–´ìš”",
                    "keywords": ["#ê°ì •ë‚˜ëˆ”"],
                    "action_items": ["ì˜¤ëŠ˜ë„ ê³ ìƒ ë§ì•˜ì–´ìš”"],
                    "success": False
                }
            
            user_messages = []
            for msg in messages:
                try:
                    if isinstance(msg, dict) and msg.get("role") == "user" and msg.get("content"):
                        user_messages.append(msg["content"])
                except Exception:
                    continue
            
            if not user_messages:
                return {
                    "summary": "ì‚¬ìš©ì ë©”ì‹œì§€ê°€ ì—†ì–´ìš”",
                    "keywords": ["#ê°ì •ë‚˜ëˆ”"],
                    "action_items": ["ì˜¤ëŠ˜ë„ ê³ ìƒ ë§ì•˜ì–´ìš”"],
                    "success": False
                }
            
            conversation_text = "\n".join(user_messages)
            
            if len(conversation_text) > 1500:
                conversation_text = conversation_text[:1500] + "..."
            
            prompt = f"""ë‹¤ìŒ ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•´ì„œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

ëŒ€í™” ë‚´ìš©:
{conversation_text}

ë¶„ì„ ìš”ì²­:
1. ì˜¤ëŠ˜ ìˆì—ˆë˜ ì¼ì„ 1-2ì¤„ë¡œ ìš”ì•½
2. ëŒ€í™”ì—ì„œ ëŠê»´ì§„ ê°ì • í‚¤ì›Œë“œ 5ê°œ ì¶”ì¶œ (ì˜ˆ: #ê¸°ì¨, #ë¶ˆì•ˆ, #ì„±ì·¨ê° ë“±)
3. ì‚¬ìš©ìì—ê²Œ ë„ì›€ì´ ë  ë”°ëœ»í•˜ê³  ì¹œê·¼í•œ ì¡°ì–¸ 3ê°œ ì œì•ˆ (ì¹œêµ¬ ê°™ì€ ë§íˆ¬ë¡œ, ~í•´ìš”/~ëë‹ˆë‹¤ êµì°¨ ì‚¬ìš©)

ì‘ë‹µ í˜•ì‹:
ìš”ì•½: [1-2ì¤„ ìš”ì•½]
ê°ì •í‚¤ì›Œë“œ: #í‚¤ì›Œë“œ1, #í‚¤ì›Œë“œ2, #í‚¤ì›Œë“œ3, #í‚¤ì›Œë“œ4, #í‚¤ì›Œë“œ5
ì•¡ì…˜ì•„ì´í…œ: 
- [~í•´ìš” ë§íˆ¬ì˜ ë”°ëœ»í•œ ì¡°ì–¸]
- [~ëë‹ˆë‹¤ ë§íˆ¬ì˜ ì¹œê·¼í•œ ì¡°ì–¸]
- [~í•´ìš” ë§íˆ¬ì˜ ê²©ë ¤ ë©”ì‹œì§€]"""

            result = self.generate_response(prompt, max_new_tokens=300, temperature=0.3)
            
            # ì‘ë‹µ íŒŒì‹±
            lines = result.strip().split('\n')
            summary = ""
            keywords = []
            action_items = []
            
            current_section = None
            
            for line in lines:
                line = line.strip()
                if line.startswith('ìš”ì•½:'):
                    summary = line.replace('ìš”ì•½:', '').strip()
                elif line.startswith('ê°ì •í‚¤ì›Œë“œ:'):
                    keyword_text = line.replace('ê°ì •í‚¤ì›Œë“œ:', '').strip()
                    keywords = [k.strip() for k in keyword_text.split(',') if k.strip()]
                elif line.startswith('ì•¡ì…˜ì•„ì´í…œ:'):
                    current_section = "actions"
                elif current_section == "actions" and line.startswith('-'):
                    action_item = line.replace('-', '').strip()
                    if action_item:
                        action_items.append(action_item)
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            if not summary:
                summary = "ì˜¤ëŠ˜ì˜ ê°ì •ì„ ë‚˜ëˆ„ì—ˆì–´ìš”"
            if not keywords:
                keywords = ["#ê°ì •ë‚˜ëˆ”"]
            if not action_items:
                action_items = ["ì˜¤ëŠ˜ë„ ê³ ìƒ ë§ì•˜ì–´ìš”"]
            
            keywords = keywords[:5]
            action_items = action_items[:3]
            
            return {
                "summary": summary,
                "keywords": keywords,
                "action_items": action_items,
                "success": True
            }
            
        except Exception as e:
            print(f"ëŒ€í™” ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                "summary": "ìš”ì•½ì„ ë§Œë“œëŠ” ì¤‘ì— ë¬¸ì œê°€ ìƒê²¼ì–´ìš”",
                "keywords": ["#ê°ì •ë‚˜ëˆ”"],
                "action_items": ["ì˜¤ëŠ˜ë„ ê³ ìƒ ë§ì•˜ì–´ìš”"],
                "success": False
            }

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def check_harmful_content(text: str) -> bool:
    """ìœ í•´ ì½˜í…ì¸  ê²€ì‚¬"""
    if not text or not isinstance(text, str):
        return False
    
    try:
        text_lower = text.lower().replace(" ", "")
        harmful_patterns = [
            "ìì‚´", "ì£½ê³ ì‹¶", "ìí•´", "ì£½ê³ ì‹¶ì–´", "ì‚¬ë¼ì§€ê³ ì‹¶", "ëë‚´ê³ ì‹¶", 
            "ì‚´ê¸°ì‹«", "ì‚´ê³ ì‹¶ì§€", "ì£½ì–´ë²„ë¦¬", "ì£½ì—ˆìœ¼ë©´", "ë² ê³ ì‹¶", "ìì‚´í•˜ê³ "
        ]
        
        return any(pattern in text_lower for pattern in harmful_patterns)
    except Exception:
        return False

def check_violence_content(text: str) -> bool:
    """í­ë ¥ ì½˜í…ì¸  ê²€ì‚¬"""
    if not text or not isinstance(text, str):
        return False
    
    try:
        text_lower = text.lower().replace(" ", "")
        violence_patterns = [
            "ë•Œë¦¬ê³ ì‹¶", "ì£½ì´ê³ ì‹¶", "ì¹¼", "ì´", "ì„±í­í–‰", "ê°•ê°„", "í­í–‰", 
            "ë•Œë ¸ë‹¤", "ë§ì•˜ë‹¤", "í˜‘ë°•", "í­ë ¥", "ì„±ì¶”í–‰"
        ]
        
        return any(pattern in text_lower for pattern in violence_patterns)
    except Exception:
        return False

def check_content_with_local_model(text: str) -> dict:
    """ë¡œì»¬ ëª¨ë¸ì„ ì‚¬ìš©í•œ ì½˜í…ì¸  ê²€ì‚¬ (ê¸°ë³¸ í‚¤ì›Œë“œ ê²€ì‚¬ ì‚¬ìš©)"""
    if not text or not isinstance(text, str):
        return {
            "flagged": False,
            "self_harm": False,
            "violence": False,
            "error": "Empty or invalid text"
        }
    
    try:
        is_self_harm = check_harmful_content(text)
        is_violence = check_violence_content(text)
        
        return {
            "flagged": is_self_harm or is_violence,
            "self_harm": is_self_harm,
            "violence": is_violence,
            "success": True
        }
        
    except Exception as e:
        return {
            "flagged": check_harmful_content(text) or check_violence_content(text),
            "self_harm": check_harmful_content(text),
            "violence": check_violence_content(text),
            "error": str(e),
            "fallback": True
        }
